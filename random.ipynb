{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import requests\n",
    "import os\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import random\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import zipfile\n",
    "from tqdm.auto import tqdm\n",
    "from typing import Dict, List, Tuple\n",
    "import cv2\n",
    "combat = \"combat\"\n",
    "rehab = \"humanitarianaid\"\n",
    "military_vehicles = \"militaryvehicles\"\n",
    "fire = \"fire\"\n",
    "destroyed_building = \"destroyedbuilding\"\n",
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def event_identification(img):        # NOTE: You can tweak this function in case you need to give more inputs \n",
    "    event_list = []\n",
    "    im5 = img[879:963,197:281] #A\n",
    "    im4 = img[678:762,670:754] #B\n",
    "    im2 = img[470:558,678:763] #C\n",
    "    im3 = img[465:552,179:266] #D\n",
    "    im1 = img[128:216,200:285] #E\n",
    "\n",
    "    event_list.append(im5)\n",
    "    event_list.append(im4)\n",
    "    event_list.append(im2)\n",
    "    event_list.append(im3)\n",
    "    event_list.append(im1)\n",
    "    # event_list.reverse()\n",
    "    cv2.imwrite(\"s1.jpg\", im1)\n",
    "    cv2.imwrite(\"s2.jpg\", im2)\n",
    "    cv2.imwrite(\"s3.jpg\", im3)\n",
    "    cv2.imwrite(\"s4.jpg\", im4)\n",
    "    cv2.imwrite(\"s5.jpg\", im5)\n",
    "    return event_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_event(image):\n",
    "    cv2.imwrite(\"a.jpg\",image)\n",
    "    from PIL import Image\n",
    "    import torchvision.transforms as transforms\n",
    "    import torch # Use the input size corresponding to the model\n",
    "    test_image = Image.open(\"a.jpg\")\n",
    "    manual_transforms = transforms.Compose([\n",
    "    transforms.Resize((150, 150), antialias=True),\n",
    "    # transforms.Resize((244, 244), antialias=True),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "    \n",
    "    \n",
    "    test_image = manual_transforms(test_image)\n",
    "    model_path = '/home/adi/GG_1267/Task_1A_git/Task_4a/modelx.pth'  #model uploaded on google drive\n",
    "    model = torch.load(model_path,map_location='cpu')\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(test_image.unsqueeze(0))\n",
    "    target_image_pred = output\n",
    "    target_image_pred_probs = torch.softmax(target_image_pred, dim=1)\n",
    "    target_image_pred_label = torch.argmax(target_image_pred_probs, dim=1)\n",
    "    class_names = [\"combat\", \"destroyedbuilding\", \"fire\", \"humanitarianaid\", \"militaryvehicles\"]\n",
    "    # os.remove(\"a.png\")\n",
    "    return class_names[target_image_pred_label.item()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification(event_list):\n",
    "    detected_list = []\n",
    "    for img_index in range(0,5):\n",
    "        img = event_list[img_index]\n",
    "        detected_event = classify_event(img)\n",
    "        print((img_index + 1), detected_event)\n",
    "        if detected_event == combat:\n",
    "            detected_list.append(\"combat\")\n",
    "        if detected_event == rehab:\n",
    "            detected_list.append(\"rehab\")\n",
    "        if detected_event == military_vehicles:\n",
    "            detected_list.append(\"militaryvehicles\")\n",
    "        if detected_event == fire:\n",
    "            detected_list.append(\"fire\")\n",
    "        if detected_event == destroyed_building:\n",
    "            detected_list.append(\"destroyedbuilding\")\n",
    "    return detected_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 combat\n",
      "2 fire\n",
      "3 destroyedbuilding\n",
      "4 militaryvehicles\n",
      "5 humanitarianaid\n",
      "['combat', 'fire', 'destroyedbuilding', 'militaryvehicles', 'rehab']\n"
     ]
    }
   ],
   "source": [
    "imager = cv2.imread(\"/home/adi/GG_1267/Task_1A_git/Task_4a/eyantra photos/saved_image24.jpg\")\n",
    "event_list = event_identification(imager)\n",
    "print(classification(event_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda_com",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
